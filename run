#!/bin/bash

# FIXME This script leaves a lot to be desired! Rather than rewrite it,
# it may be easier to incorporate into the osdataproc Python CLI...

set -e
OSDP_HOME=$(dirname "$0")

export TF_IN_AUTOMATION=1 # Limit Terraform output
export TF_VAR_username=$OS_USERNAME
export TF_VAR_cluster_name=${2}
# generate API key for netdata
export NETDATA_API_KEY=$(uuidgen)
export TF_VAR_netdata_api_key=${NETDATA_API_KEY}
export CLUSTER_PREFIX="${OS_USERNAME}-${TF_VAR_cluster_name}"

# Runs on terraform apply error - delete created resources
cleanup () {
  echo "ERROR: Only partial configuration could complete. Cleaning up created resources..."
  sleep 3
  cd ${OSDP_HOME}/terraform
  export TF_WARN_OUTPUT_ERRORS=1 # Destroy even if output variables do not evaluate
  terraform workspace select $TF_VAR_cluster_name && \
  terraform destroy -auto-approve && \
  terraform workspace select default && \
  terraform workspace delete $TF_VAR_cluster_name
  echo "Tidy up complete. Please try again. Check that enough resources exist."
}

get_apply_vars () {
  input_args=($@)
  if [[ ${3} =~ ^[0-9]+$ ]] ; then
    export TF_VAR_workers=$((${3}))
  fi
  keyfile="${4/#\~/$HOME}" # expand tilde to $HOME
  if [[ -f ${keyfile} ]] ; then
    export TF_VAR_identity_file=$(< ${keyfile})
  else
    echo "The file could not be found. Please enter a valid path to a public key."
    exit 1
  fi

  # FIXME Oh Jesus, God, no!...
  tfvars=(flavor_name network_name lustre_network image_name nfs_volume volume_size device_name spark_master_public_ip)
  # Update tfvars variables if set, otherwise use defaults
  for i in "${!tfvars[@]}" ; do
    if [ "${input_args[i+4]}" != None ] ; then
      export TF_VAR_${tfvars[i]}=${input_args[i+4]}
    fi
  done
}

ansible() {
  export ANSIBLE_HOST_KEY_CHECKING=False
  ansible-playbook ${OSDP_HOME}/ansible/main.yml \
                   -i ${OSDP_HOME}/terraform/terraform.tfstate.d/${TF_VAR_cluster_name}/hosts_${1} \
                   -e 'ansible_python_interpreter=/usr/bin/python3' \
                   -e '@../vars.yml' \
                   --limit spark_${1} \
                   2>&1 \
  | tee ${OSDP_HOME}/terraform/terraform.tfstate.d/${TF_VAR_cluster_name}/ansible-${1}.log
}

cd ${OSDP_HOME}/terraform
case ${1} in
  init)
    terraform init -input=false
    ;;
  apply)
    trap cleanup ERR
    get_apply_vars $@
    echo "Password for web authentication and encrypted volume: "
    read -sr PASSWORD
    export PASSWORD=$PASSWORD
    terraform workspace select ${2} || terraform workspace new ${2}
    terraform plan -out="terraform.tfstate.d/${2}/plan" -input=false
    terraform apply -input=false "terraform.tfstate.d/${2}/plan"
    terraform output -json > terraform.tfstate.d/${2}/outputs.json
    ansible "master"
    exit 0
    ;;
  destroy)
    if ! terraform workspace select ${2} ; then
      echo "Cluster not found"
    else
      terraform workspace select ${2}
      terraform destroy -var-file=terraform.tfstate.d/${2}/destroy.tfvars
      terraform workspace select default
      terraform workspace delete ${2}
    fi
    exit 0
    ;;
  reboot)
    nodes=${OS_USERNAME}-${2}-worker
    if ! terraform workspace select ${2} ; then
      echo "Cluster not found"
    else
      echo "Nodes to reboot: "
      nova list | grep ${nodes} | cut -d '|' -f 3
      read -p "Are you sure you want to reboot all ${nodes} nodes? (y/n) " -n 1 -r
      echo
      if [[ $REPLY =~ ^[Yy]$ ]] ; then
        echo "Rebooting worker nodes..."
        nova list | grep ${nodes} | cut -d '|' -f 2 | xargs nova reboot
      else
        echo "Reboot cancelled"
      fi
    fi
    exit 0
    ;;
  *)
    exit 1
    ;;
esac
