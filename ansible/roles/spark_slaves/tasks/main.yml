---

- name: Extract Spark distribution
  become: yes
  unarchive:
          src: "{{ spark_download_dir }}/spark-{{ spark_version }}.tgz"
          dest: "{{ spark_install_dir }}"
          owner: "{{ spark_user }}"
          group: "{{ spark_group }}"
          extra_opts: [--strip-components=1]
          keep_newer: yes
          remote_src: yes

- name: Start Spark slave
  service: name=spark-slave state=started enabled=yes

  # virtualenv python needs to be present on all slave nodes, so create it here
- name: Create virtualenv
  become: yes
  become_user: "{{ spark_user }}"
  pip:
          state: present
          name: pyspark
          virtualenv: "{{ venv_dir }}"
          virtualenv_command: /usr/bin/python3 -m venv

- name: Install Netdata
  shell: "cd {{ netdata_dir }} && ./netdata-installer.sh --dont-wait"

- name: Wait for master nfs server to come up
  wait_for:
          state: started
          host: "{{ spark_master_private_ip }}"
          port: 2049
          sleep: 5
          timeout: 86400
  when: nfs_volume != ''

- name: Mount data directory
  become: yes
  mount:
          path: /home/ubuntu/data
          src: "{{ spark_master_private_ip }}:/home/ubuntu/data"
          fstype: nfs
          state: mounted
  when: nfs_volume != ''
